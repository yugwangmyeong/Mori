"""
WebRTC ì—°ê²° ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¸ë“¤ëŸ¬
"""
import asyncio
import logging
import numpy as np
from typing import Optional, List, Callable
from collections import deque
from fastapi import WebSocket
from aiortc import RTCPeerConnection, RTCSessionDescription, RTCIceCandidate, MediaStreamTrack, RTCDataChannel
from aiortc.contrib.media import MediaPlayer, MediaRelay
from aiortc.sdp import candidate_from_sdp
import json
import wave
import os
import time
from datetime import datetime

from audio_encoder import AudioEncoder
from realtime_stt_client import RealtimeSttClient
from llm_service import LLMService
from typing import Optional, Callable, Awaitable
logger = logging.getLogger(__name__)


# AudioChunkBufferëŠ” AudioEncoder í´ë˜ìŠ¤ë¡œ ëŒ€ì²´ë¨


class AudioTrackReceiver(MediaStreamTrack):
    """WebRTCì—ì„œ ë°›ì€ ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ (server_vad ëª¨ë“œ: ê³„ì† appendë§Œ ìˆ˜í–‰)"""
    kind = "audio"
    
    def __init__(self, track, stt_client: Optional[RealtimeSttClient], mic_enabled_callback: Optional[Callable[[], bool]] = None, digital_gain_db: float = 6.0):
        super().__init__()
        self.track = track
        self.stt_client = stt_client  # STT í´ë¼ì´ì–¸íŠ¸
        self.mic_enabled_callback = mic_enabled_callback  # ë§ˆì´í¬ ìƒíƒœ í™•ì¸ ì½œë°±
        
        # ì˜¤ë””ì˜¤ ì¸ì½”ë” (ë²„í¼ ê¸°ë°˜, 24kHz, 20ms ì²­í¬)
        # digital_gain_db: ì…ë ¥ ìŒëŸ‰ ì¦ê°€ (peak 3000~15000 ë²”ìœ„ë¡œ ì¡°ì •)
        self.audio_encoder = AudioEncoder(digital_gain_db=digital_gain_db)
    
    async def recv(self):
        """ì˜¤ë””ì˜¤ í”„ë ˆì„ ìˆ˜ì‹  - server_vad ëª¨ë“œ: ê³„ì† appendë§Œ ìˆ˜í–‰ (commit ì—†ìŒ)"""
        frame = await self.track.recv()
        
        # STT í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ í”„ë ˆì„ë§Œ ë°˜í™˜
        if not self.stt_client:
            return frame
        
        # ë§ˆì´í¬ê°€ êº¼ì ¸ ìˆìœ¼ë©´ STT ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°
        if self.mic_enabled_callback and not self.mic_enabled_callback():
            return frame
        
        # STTìš© 24kHz ë³€í™˜ ë° 20ms ì²­í¬ ìƒì„± (ë²„í¼ ê¸°ë°˜)
        stt_chunks, stt_metadata = self.audio_encoder.process_frame(frame)
        
        if not stt_chunks:
            return frame
        
        # ì˜¤ë””ì˜¤ ì—ë„ˆì§€ê°€ ë§¤ìš° ë‚®ìœ¼ë©´ ë§ˆì´í¬ê°€ êº¼ì§„ ê²ƒìœ¼ë¡œ ê°„ì£¼
        rms = stt_metadata.get('rms', 0.0)
        peak = stt_metadata.get('peak', 0)
        if rms < 0.001 and peak < 100:  # ë§¤ìš° ë‚®ì€ ì—ë„ˆì§€
            return frame
        
        # server_vad ëª¨ë“œ: ê³„ì† appendë§Œ ìˆ˜í–‰ (ì„œë²„ê°€ í„´ íŒë‹¨)
        if stt_chunks:
            for chunk_bytes in stt_chunks:
                # chunk_bytes ê²€ì¦ (960 bytes @ 24kHz)
                if len(chunk_bytes) != 960:
                    continue
                
                # appendë§Œ ìˆ˜í–‰ (commitì€ ì„œë²„ê°€ íŒë‹¨)
                await self.stt_client.append_audio(chunk_bytes)
        
        return frame
    
class AudioTrackSender(MediaStreamTrack):
    """TTS ì˜¤ë””ì˜¤ë¥¼ WebRTCë¡œ ì†¡ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    kind = "audio"
    
    def __init__(self):
        super().__init__()
        self._queue = asyncio.Queue()
        self._closed = False
        
    async def recv(self):
        """ì˜¤ë””ì˜¤ í”„ë ˆì„ ì†¡ì¶œ (20ms ë‹¨ìœ„)"""
        if self._closed:
            raise Exception("Track closed")
        
        # íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        audio_data = await self._queue.get()
        return audio_data
    
    async def push_audio(self, audio_frame):
        """TTSì—ì„œ ìƒì„±ëœ ì˜¤ë””ì˜¤ë¥¼ íì— ì¶”ê°€"""
        if not self._closed:
            await self._queue.put(audio_frame)
    
    def close(self):
        """íŠ¸ë™ ì¢…ë£Œ"""
        self._closed = True


class WebRTCHandler:
    """WebRTC ì—°ê²° ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, session_id: str, websocket: Optional[WebSocket] = None, enable_stt: bool = True):
        self.session_id = session_id
        self.websocket = websocket  # WebSocketì€ ì„ íƒì  (DataChannel ì‚¬ìš© ì‹œ None)
        self.enable_stt = enable_stt  # STT í™œì„±í™” ì—¬ë¶€
        self.pc: Optional[RTCPeerConnection] = None
        self.data_channel: Optional[RTCDataChannel] = None  # DataChannel
        
        # STT í´ë¼ì´ì–¸íŠ¸ (Realtime Transcription)
        self.stt_client: Optional[RealtimeSttClient] = None
        self.receiver_task: Optional[asyncio.Task] = None
        
        # ë¡œì»¬ VAD ëª¨ë“œ: VADSegmenterê°€ ë§ ëì„ ê°ì§€í•˜ë©´ commit í˜¸ì¶œ
        
        # WAV ë¤í”„ (ë””ë²„ê¹…ìš©)
        self.debug_dump_wav = True  # ê°œë°œìš© í”Œë˜ê·¸
        self.stt_dump_seq = 0  # WAV ë¤í”„ ì‹œí€€ìŠ¤ ë²ˆí˜¸
        self.stt_accum_pcm16 = bytearray()  # WAV ë¤í”„ìš© ëˆ„ì  ë²„í¼
        
        # ì¹´ìš´í„° ê²€ì¦
        self.queued_chunks = 0  # íì— ë„£ì€ ì²­í¬ ìˆ˜
        self.sent_chunks = 0  # ì‹¤ì œë¡œ ì „ì†¡í•œ ì²­í¬ ìˆ˜
        self.appended_chunks = 0  # appendí•œ ì²­í¬ ìˆ˜
        
        # ì˜¤ë””ì˜¤ ì†¡ì¶œ íŠ¸ë™
        self.audio_sender: Optional[AudioTrackSender] = None
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_speaking = False  # AIê°€ ë§í•˜ê³  ìˆëŠ”ì§€
        self.current_turn_cancelled = False  # Barge-in í”Œë˜ê·¸
        self.mic_enabled = True  # ë§ˆì´í¬ í™œì„±í™” ìƒíƒœ (ê¸°ë³¸ê°’: True)
        
        # LLM ì„œë¹„ìŠ¤
        self.llm_service: Optional[LLMService] = None
        
        # í„´ ìƒíƒœ ë¨¸ì‹  (server_vad ê¸°ë°˜)
        self.turn_id = 0  # í˜„ì¬ í„´ ID (ì¦ê°€ê°’)
        self.in_speech = False  # í˜„ì¬ ë°œí™” ì¤‘ì¸ì§€
        self.turn_text_buffer = ""  # í˜„ì¬ í„´ ëˆ„ì  í…ìŠ¤íŠ¸
        self.awaiting_final = False  # speech_stopped ì´í›„ final/completed ê¸°ë‹¤ë¦¬ëŠ” ìƒíƒœ
        self.final_timeout_task: Optional[asyncio.Task] = None  # final íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬
        self._turn_lock = asyncio.Lock()  # í„´ ìƒíƒœ ì ‘ê·¼ ë½
        
    async def handle_connection(self):
        """WebRTC ì—°ê²° ì²˜ë¦¬"""
        self.pc = RTCPeerConnection()
        
        # ì˜¤ë””ì˜¤ ì†¡ì¶œ íŠ¸ë™ ìƒì„±
        self.audio_sender = AudioTrackSender()
        self.pc.addTrack(self.audio_sender)
        
        # ICE candidate ì²˜ë¦¬
        @self.pc.on("icecandidate")
        async def on_icecandidate(candidate):
            if candidate:
                # WebSocketì´ ìˆìœ¼ë©´ WebSocketìœ¼ë¡œ, ì—†ìœ¼ë©´ DataChannelë¡œ
                # í•˜ì§€ë§Œ ICE candidatesëŠ” ì—°ê²° ì „ì— ë°œìƒí•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œ
                # (ICE candidatesëŠ” ì´ë¯¸ SDPì— í¬í•¨ë˜ì–´ ìˆìŒ)
                pass
        
        # ì—°ê²° ìƒíƒœ ë³€ê²½
        @self.pc.on("connectionstatechange")
        async def on_connectionstatechange():
            logger.info(f"Connection state: {self.pc.connectionState}")
            if self.pc.connectionState == "failed":
                await self.cleanup()
        
        # DataChannel ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        self._setup_datachannel_handlers()
        
        # ì˜¤ë””ì˜¤ íŠ¸ë™ ìˆ˜ì‹  ì²˜ë¦¬
        @self.pc.on("track")
        async def on_track(track):
            if track.kind == "audio":
                logger.info("Audio track received")
                # STT í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ AudioTrackReceiver ìƒì„± (server_vad ëª¨ë“œ)
                if self.stt_client:
                    receiver = AudioTrackReceiver(
                        track, 
                        self.stt_client,
                        mic_enabled_callback=lambda: self.mic_enabled,
                        digital_gain_db=6.0,  # ì…ë ¥ ê²Œì¸ 6dB (peak 3000~15000 ë²”ìœ„ë¡œ ì¡°ì •)
                        on_segment_commit=self._handle_segment_commit
                    )
                    asyncio.create_task(self._audio_receive_loop(receiver))
                else:
                    logger.warning("STT client not initialized, audio processing skipped")
        
        # WebSocketì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹œê·¸ë„ë§ ë©”ì‹œì§€ ì²˜ë¦¬ (ì´ì „ ë°©ì‹)
        if self.websocket:
            while True:
                try:
                    message = await self.websocket.receive_json()
                    await self._handle_signaling(message)
                except Exception as e:
                    logger.error(f"Signaling error: {e}", exc_info=True)
                    break
    
    async def _audio_receive_loop(self, receiver: AudioTrackReceiver):
        """ì˜¤ë””ì˜¤ ìˆ˜ì‹  ë£¨í”„"""
        frame_count = 0
        last_log_time = 0
        try:
            while True:
                frame = await receiver.recv()
                frame_count += 1
                
                # 1ì´ˆë§ˆë‹¤ í”„ë ˆì„ ìˆ˜ì‹  ìƒíƒœ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
                import time
                current_time = time.time()
                if current_time - last_log_time >= 1.0:
                    last_log_time = current_time
                
                # recv() ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
        except Exception as e:
            # ì •ìƒ ì¢…ë£Œì¸ ê²½ìš° (íŠ¸ë™ ì¢…ë£Œ, ì—°ê²° ì¢…ë£Œ ë“±)
            error_type = type(e).__name__
            error_msg = str(e) if str(e) else f"{error_type} (no message)"
            
            # ì •ìƒ ì¢…ë£Œë¡œ ë³´ì´ëŠ” ì˜ˆì™¸ëŠ” ì—ëŸ¬ê°€ ì•„ë‹Œ ì •ë³´ ë¡œê·¸ë¡œ ì²˜ë¦¬
            if error_type in ("MediaStreamError", "ConnectionClosed", "ConnectionClosedOK") or \
               "closed" in error_msg.lower() or "ended" in error_msg.lower():
                logger.info(f"Audio receive loop ended: {error_type} - {error_msg}")
            else:
                # ì‹¤ì œ ì—ëŸ¬ì¸ ê²½ìš°ë§Œ ì—ëŸ¬ ë¡œê·¸
                logger.error(f"Audio receive loop error: {error_type} - {error_msg}", exc_info=True)
            
            logger.info(f"ğŸ“Š ì˜¤ë””ì˜¤ ìˆ˜ì‹  ë£¨í”„ ì¢…ë£Œ (ì´ {frame_count}ê°œ í”„ë ˆì„ ìˆ˜ì‹ ë¨)")
    
    async def _handle_ice_candidate(self, msg: dict):
        """
        ICE candidate ì²˜ë¦¬
        msg can be:
          {type:'ice-candidate', candidate:'candidate:...', sdpMid:'0', sdpMLineIndex:0}
        or
          {type:'ice-candidate', candidate:{candidate:'candidate:...', sdpMid:'0', sdpMLineIndex:0}}
        """
        c = msg.get("candidate")
        if not c:
            logger.debug("ICE candidate message missing candidate field")
            return

        # normalize nested format
        if isinstance(c, dict):
            candidate_sdp = c.get("candidate")
            sdp_mid = c.get("sdpMid")
            sdp_mline_index = c.get("sdpMLineIndex")
        else:
            candidate_sdp = c
            sdp_mid = msg.get("sdpMid")
            sdp_mline_index = msg.get("sdpMLineIndex")

        if not candidate_sdp:
            logger.warning("ICE candidate message missing candidate SDP string")
            return

        # PeerConnectionì´ ìœ íš¨í•œì§€ í™•ì¸
        if not self.pc or self.pc.connectionState == "closed":
            logger.debug("PeerConnection not available or closed, skipping ICE candidate")
            return

        try:
            # candidate_from_sdpë¡œ íŒŒì‹±
            cand = candidate_from_sdp(candidate_sdp)
            if sdp_mid is not None:
                cand.sdpMid = sdp_mid
            if sdp_mline_index is not None:
                cand.sdpMLineIndex = sdp_mline_index
            
            await self.pc.addIceCandidate(cand)
            logger.info("ICE candidate added (mid=%s, mline=%s)", sdp_mid, sdp_mline_index)
        except Exception as e:
            # candidate ì²˜ë¦¬ ì‹¤íŒ¨í•´ë„ ì„¸ì…˜ì„ ëŠì§€ ì•ŠìŒ
            logger.warning("Failed to add ICE candidate: %s | msg=%s", e, msg)
    
    async def handle_offer(self, sdp_offer: str) -> str:
        """
        HTTP POSTë¡œ ë°›ì€ offerë¥¼ ì²˜ë¦¬í•˜ê³  answerë¥¼ ë°˜í™˜
        """
        # PeerConnection ìƒì„±
        self.pc = RTCPeerConnection()
        
        # ì˜¤ë””ì˜¤ ì†¡ì¶œ íŠ¸ë™ ìƒì„±
        self.audio_sender = AudioTrackSender()
        self.pc.addTrack(self.audio_sender)
        
        # DataChannel ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        self._setup_datachannel_handlers()
        
        # ì—°ê²° ìƒíƒœ ë³€ê²½
        @self.pc.on("connectionstatechange")
        async def on_connectionstatechange():
            logger.info(f"Connection state: {self.pc.connectionState}")
            if self.pc.connectionState == "failed":
                await self.cleanup()
        
        # STT íŒŒì´í”„ë¼ì¸ ë¨¼ì € ì´ˆê¸°í™” (ì˜¤ë””ì˜¤ íŠ¸ë™ í•¸ë“¤ëŸ¬ ë“±ë¡ ì „ì—)
        if self.enable_stt:
            try:
                await self._setup_stt_pipeline()
            except Exception as e:
                logger.error(f"Failed to setup STT during handle_offer: {e}", exc_info=True)
                # STT ì‹¤íŒ¨í•´ë„ WebRTC ì—°ê²°ì€ ê³„ì† ì§„í–‰
        else:
            logger.info("STT is disabled for this session - WebRTC call only")
        
        # ì˜¤ë””ì˜¤ íŠ¸ë™ ìˆ˜ì‹  ì²˜ë¦¬ (STT íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í›„)
        @self.pc.on("track")
        async def on_track(track):
            if track.kind == "audio":
                logger.info("âœ… Audio track received from client")
                # STT í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ AudioTrackReceiver ìƒì„± (server_vad ëª¨ë“œ)
                if self.stt_client:
                    receiver = AudioTrackReceiver(
                        track, 
                        self.stt_client,
                        mic_enabled_callback=lambda: self.mic_enabled,
                        digital_gain_db=6.0  # ì…ë ¥ ê²Œì¸ 6dB (peak 3000~15000 ë²”ìœ„ë¡œ ì¡°ì •)
                    )
                    asyncio.create_task(self._audio_receive_loop(receiver))
                else:
                    logger.warning("STT client not initialized, audio processing skipped")
        
        # offer ì„¤ì •
        offer = RTCSessionDescription(sdp=sdp_offer, type="offer")
        await self.pc.setRemoteDescription(offer)
        
        # answer ìƒì„±
        answer = await self.pc.createAnswer()
        await self.pc.setLocalDescription(answer)
        
        logger.info("âœ… WebRTC answer ìƒì„± ì™„ë£Œ")
        
        return self.pc.localDescription.sdp
    
    async def _wait_for_connection(self):
        """ì—°ê²° ì™„ë£Œ ëŒ€ê¸° (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
        try:
            # ICE ì—°ê²° ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
            for _ in range(100):  # 100 * 0.1ì´ˆ = 10ì´ˆ
                if self.pc and self.pc.connectionState == "connected":
                    logger.info("âœ… WebRTC connection established")
                    break
                await asyncio.sleep(0.1)
        except Exception as e:
            logger.error(f"Error waiting for connection: {e}")
    
    def _setup_datachannel_handlers(self):
        """DataChannel ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •"""
        @self.pc.on("datachannel")
        def on_datachannel(channel: RTCDataChannel):
            logger.info(f"DataChannel received: {channel.label}")
            self.data_channel = channel
            
            @channel.on("message")
            def on_message(message):
                try:
                    if isinstance(message, str):
                        data = json.loads(message)
                        logger.debug(f"DataChannel message received: {data}")
                        # ë§ˆì´í¬ ìƒíƒœ ë©”ì‹œì§€ ì²˜ë¦¬
                        asyncio.create_task(self._handle_datachannel_message(data))
                except Exception as e:
                    logger.error(f"Error processing DataChannel message: {e}")
            
            @channel.on("open")
            def on_open():
                logger.info("âœ… DataChannel opened")
            
            @channel.on("close")
            def on_close():
                logger.info("DataChannel closed")
    
    async def _handle_datachannel_message(self, data: dict):
        """DataChannel ë©”ì‹œì§€ ì²˜ë¦¬"""
        msg_type = data.get("type")
        
        if msg_type == "mic.enabled" or msg_type == "mic.on":
            self.mic_enabled = True
            logger.info("ğŸ¤ Microphone enabled")
        elif msg_type == "mic.disabled" or msg_type == "mic.off":
            self.mic_enabled = False
            logger.info("ğŸ”‡ Microphone disabled")
            # ë§ˆì´í¬ê°€ êº¼ì§€ë©´ STT í´ë¼ì´ì–¸íŠ¸ ë²„í¼ ì •ë¦¬ (server_vad ëª¨ë“œì—ì„œëŠ” clear ì‚¬ìš© ì•ˆ í•¨)
            # server_vad ëª¨ë“œì—ì„œëŠ” ì„œë²„ê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ë³„ë„ ì‘ì—… ë¶ˆí•„ìš”
        elif msg_type == "mic.toggle":
            self.mic_enabled = not self.mic_enabled
            logger.info(f"ğŸ¤ Microphone toggled: {'ON' if self.mic_enabled else 'OFF'}")
        # ê¸°íƒ€ ë©”ì‹œì§€ëŠ” ë¬´ì‹œ
    
    async def send_json(self, payload: dict):
        """
        DataChannelë¡œ JSON ë©”ì‹œì§€ ì „ì†¡
        
        Args:
            payload: ì „ì†¡í•  ë”•ì…”ë„ˆë¦¬ (JSONìœ¼ë¡œ ì§ë ¬í™”ë¨)
        
        Returns:
            bool: ì „ì†¡ ì„±ê³µ ì—¬ë¶€
        """
        # DataChannel ì¡´ì¬ í™•ì¸
        if not self.data_channel:
            logger.warning(f"DC_SEND_SKIP channel_not_exist type={payload.get('type', 'unknown')}")
            return False
        
        # readyState í™•ì¸
        if self.data_channel.readyState != "open":
            state = self.data_channel.readyState
            logger.warning(f"DC_SEND_SKIP channel_not_open state={state} type={payload.get('type', 'unknown')}")
            return False
        
        try:
            # JSON ì§ë ¬í™”
            message_str = json.dumps(payload)
            message_bytes = len(message_str.encode('utf-8'))
            
            # ì „ì†¡
            self.data_channel.send(message_str)
            
            # ì„±ê³µ ë¡œê·¸
            msg_type = payload.get('type', 'unknown')
            turn_id = payload.get('turn_id')
            if turn_id is not None:
                logger.info(f"DC_SEND_OK type={msg_type} turn_id={turn_id} bytes={message_bytes}")
            else:
                logger.info(f"DC_SEND_OK type={msg_type} bytes={message_bytes}")
            
            return True
            
        except Exception as e:
            msg_type = payload.get('type', 'unknown')
            logger.error(f"DC_SEND_ERR type={msg_type} error={str(e)}", exc_info=True)
            return False
    
    async def _send_datachannel_message(self, message: dict):
        """DataChannelë¡œ ë©”ì‹œì§€ ì „ì†¡ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€, ë‚´ë¶€ì ìœ¼ë¡œ send_json ì‚¬ìš©)"""
        await self.send_json(message)
    
    async def _handle_signaling(self, message: dict):
        """WebRTC ì‹œê·¸ë„ë§ ë©”ì‹œì§€ ì²˜ë¦¬ (WebSocket ë°©ì‹ìš©)"""
        msg_type = message.get("type")
        
        if msg_type == "offer":
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° offer ë°›ìŒ
            offer = RTCSessionDescription(
                sdp=message["sdp"],
                type="offer"
            )
            await self.pc.setRemoteDescription(offer)
            
            # answer ìƒì„±
            answer = await self.pc.createAnswer()
            await self.pc.setLocalDescription(answer)
            
            # answer ì „ì†¡ (WebSocket)
            if self.websocket:
                await self.websocket.send_json({
                    "type": "answer",
                    "sdp": self.pc.localDescription.sdp
                })
            
        elif msg_type == "ice-candidate":
            # ICE candidate ì²˜ë¦¬
            await self._handle_ice_candidate(message)
    
    async def _setup_stt_pipeline(self):
        """STT íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (server_vad ëª¨ë“œ: Realtime STTê°€ í„´ì„ íŒë‹¨)"""
        if not self.enable_stt:
            return
        
        logger.info(f"[STT Setup] Starting STT pipeline setup for session: {self.session_id} (server_vad mode)")
        
        try:
            # LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            self.llm_service = LLMService()
            logger.info("âœ… [STT Setup] LLM service initialized")
            
            # STT í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì—°ê²°
            self.stt_client = RealtimeSttClient(self.session_id)
            await self.stt_client.connect()
            logger.info("âœ… [STT Setup] STT client connected (Local VAD mode)")
            
            # ë¡œì»¬ VAD ëª¨ë“œ: VADSegmenterê°€ ë§ ëì„ ê°ì§€í•˜ë©´ commit í˜¸ì¶œ
            
            # Receiver ì›Œì»¤ ì‹œì‘
            self.receiver_task = asyncio.create_task(
                self._stt_receiver_worker()
            )
            logger.info("âœ… [STT Setup] STT receiver worker started")
            
        except Exception as e:
            logger.error(f"âŒ [STT Setup] Failed to setup STT pipeline: {e}", exc_info=True)
            self.stt_client = None
    
    # server_vad ëª¨ë“œ: Realtime STTê°€ í„´ì„ íŒë‹¨
    
    async def _on_speech_started(self):
        """server_vad speech_started ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        async with self._turn_lock:
            self.turn_id += 1
            self.in_speech = True
            self.turn_text_buffer = ""
            self.awaiting_final = False
            
            # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì·¨ì†Œ (ì´ì „ í„´ì˜ íƒ€ì„ì•„ì›ƒì´ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŒ)
            if self.final_timeout_task and not self.final_timeout_task.done():
                self.final_timeout_task.cancel()
                self.final_timeout_task = None
            
            logger.info(f"ğŸ”Š VAD_START turn_id={self.turn_id}")
            
            # í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
            await self.send_json({
                "type": "vad.speech_started",
                "turn_id": self.turn_id
            })
    
    async def _on_speech_stopped(self):
        """server_vad speech_stopped ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        async with self._turn_lock:
            self.in_speech = False
            self.awaiting_final = True
            
            logger.info(f"ğŸ”‡ VAD_STOP turn_id={self.turn_id} buffer_len={len(self.turn_text_buffer)}")
            
            # í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
            await self.send_json({
                "type": "vad.speech_stopped",
                "turn_id": self.turn_id
            })
            
            # final íƒ€ì„ì•„ì›ƒ ì‹œì‘ (2.0ì´ˆ)
            self.final_timeout_task = asyncio.create_task(self._handle_final_timeout())
    
    async def _handle_final_timeout(self):
        """speech_stopped ì´í›„ final íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ (2.0ì´ˆ í›„ LLM í˜¸ì¶œ)"""
        try:
            await asyncio.sleep(2.0)
            
            async with self._turn_lock:
                # ì´ë¯¸ finalì´ ì™”ìœ¼ë©´ ìŠ¤í‚µ
                if not self.awaiting_final:
                    return
                
                # ìµœì¢… í…ìŠ¤íŠ¸ ê²°ì •
                final_text = self.turn_text_buffer.strip()
                if not final_text:
                    final_text = "[inaudible]"
                
                text_len = len(final_text)
                logger.info(f"âœ… STT_FINAL turn_id={self.turn_id} text_len={text_len} (timeout) text=\"{final_text}\"")
                
                # í´ë¼ì´ì–¸íŠ¸ë¡œ final ì „ì†¡
                await self.send_json({
                    "type": "stt.final",
                    "turn_id": self.turn_id,
                    "text": final_text
                })
                
                self.awaiting_final = False
                current_turn_id = self.turn_id
            
            # ë½ í•´ì œ í›„ LLM í˜¸ì¶œ
            await self._call_llm_for_turn(current_turn_id, final_text)
            
        except asyncio.CancelledError:
            # finalì´ ì™€ì„œ ì·¨ì†Œëœ ê²½ìš° ì •ìƒ ë™ì‘
            pass
        except Exception as e:
            logger.error(f"Final timeout error for turn {self.turn_id}: {e}", exc_info=True)
    
    async def _call_llm_for_turn(self, turn_id: int, transcript_text: str):
        """í„´ì— ëŒ€í•´ LLM í˜¸ì¶œ ë° ì‘ë‹µ ì „ì†¡"""
        if not self.llm_service:
            logger.warning(f"LLM service not available for turn {turn_id}")
            return
        
        try:
            logger.info(f"ğŸ¤– LLM_REQ turn_id={turn_id} input_chars={len(transcript_text)} input=\"{transcript_text}\"")
            
            # LLM í˜¸ì¶œ (ê°„ë‹¨í•œ 1íšŒ ìš”ì²­)
            response_text = ""
            async for token in self.llm_service.stream_response(transcript_text):
                response_text += token
            
            logger.info(f"ğŸ¤– LLM_RESP turn_id={turn_id} output_chars={len(response_text)} output=\"{response_text}\"")
            
            # DataChannelë¡œ ì‘ë‹µ ì „ì†¡
            await self.send_json({
                "type": "llm.response",
                "turn_id": turn_id,
                "text": response_text
            })
            
        except Exception as e:
            logger.error(f"LLM call error for turn {turn_id}: {e}", exc_info=True)
            await self.send_json({
                "type": "llm.error",
                "turn_id": turn_id,
                "message": str(e)
            })
    
    async def _dump_wav_file(self):
        """WAV ë¤í”„ ì €ì¥ (OpenAIë¡œ ë³´ë‚´ëŠ” ìµœì¢… 24kHz PCM16)"""
        try:
            if len(self.stt_accum_pcm16) == 0:
                return
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            dump_dir = "stt_dumps"
            os.makedirs(dump_dir, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„±
            self.stt_dump_seq += 1
            stt_stats = self.stt_client.get_stats() if self.stt_client else {}
            sample_rate = stt_stats.get('sample_rate', 24000)  # 24kHz ê¸°ë³¸
            duration_ms = self.appended_chunks * 20  # 20ms per chunk
            filename = f"{dump_dir}/stt_session_{self.session_id}_{self.stt_dump_seq:04d}_{duration_ms}ms_{sample_rate//1000}k.wav"
            
            # WAV íŒŒì¼ ì €ì¥ (24kHz ê¸°ì¤€) - ì¬ìƒ ì‹œ 24kHzë¡œ ì„¤ì •í•´ì•¼ ì •ìƒ ìŒì„±ì²˜ëŸ¼ ë“¤ë¦¼
            with wave.open(filename, 'wb') as wav_file:
                wav_file.setnchannels(1)  # mono
                wav_file.setsampwidth(2)  # 16-bit = 2 bytes
                wav_file.setframerate(sample_rate)  # 24kHz (ì¤‘ìš”: ì¬ìƒ ì‹œ ê°™ì€ rateë¡œ ì„¤ì •)
                wav_file.writeframes(bytes(self.stt_accum_pcm16))
            
            if os.path.exists(filename):
                file_size = os.path.getsize(filename)
                logger.debug(f"WAV dumped: {filename} ({duration_ms}ms, {file_size} bytes, {sample_rate}Hz)")
        
        except Exception as e:
            logger.error(f"STT: Error dumping WAV: {e}", exc_info=True)
    
    async def _stt_receiver_worker(self):
        """STT ê²°ê³¼ ìˆ˜ì‹  ì›Œì»¤ (partial/final ì „ì‚¬ ê²°ê³¼ ì²˜ë¦¬)"""
        if not self.stt_client:
            return
        
        # STT í†µê³„ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘ (10ì´ˆë§ˆë‹¤ í™•ì¸)
        async def monitor_stt_stats():
            while True:
                await asyncio.sleep(10.0)
                if self.stt_client:
                    stats = self.stt_client.get_stats()
                    appended_chunks = stats.get('appended_chunks', 0)
                    buffered_ms = stats.get('buffered_ms', 0)
                    if appended_chunks == 0:
                        logger.warning(f"âš ï¸ STT stats check: appended_chunks=0 (no audio sent to STT!)")
                    else:
                        logger.info(f"ğŸ“Š STT stats: {appended_chunks} chunks appended, {buffered_ms}ms buffered")
        
        monitor_task = asyncio.create_task(monitor_stt_stats())
        
        try:
            await self.stt_client.start_receiver_loop(
                on_partial=self._on_stt_partial,
                on_final=self._on_stt_final,
                on_error=self._on_stt_error,
                on_speech_started=self._on_speech_started,
                on_speech_stopped=self._on_speech_stopped
            )
        except asyncio.CancelledError:
            logger.debug("STT receiver worker cancelled")
            monitor_task.cancel()
        except Exception as e:
            logger.error(f"STT receiver worker error: {e}", exc_info=True)
            monitor_task.cancel()
    
    async def _on_stt_partial(self, text: str):
        """STT partial/delta ê²°ê³¼ ì²˜ë¦¬ (í„´ ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜)"""
        if not text or not text.strip():
            return
        
        text_clean = text.strip()
        
        async with self._turn_lock:
            # in_speech ë˜ëŠ” awaiting_final ìƒíƒœì¼ ë•Œë§Œ ëˆ„ì 
            if self.in_speech or self.awaiting_final:
                self.turn_text_buffer += text_clean
                total_len = len(self.turn_text_buffer)
                logger.info(f"ğŸ“ STT_DELTA turn_id={self.turn_id} delta=\"{text_clean}\" total_len={total_len} total=\"{self.turn_text_buffer}\"")
                
                # í”„ë¡ íŠ¸ì—”ë“œë¡œ partial ì „ì†¡
                await self.send_json({
                    "type": "stt.partial",
                    "turn_id": self.turn_id,
                    "delta": text_clean,
                    "text": self.turn_text_buffer
                })
    
    async def _on_stt_final(self, text: str):
        """STT final/completed ê²°ê³¼ ì²˜ë¦¬ (í„´ ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜, LLM í˜¸ì¶œ)"""
        text_clean = text.strip() if text else ""
        
        async with self._turn_lock:
            # awaiting_final ìƒíƒœê°€ ì•„ë‹ˆë©´ ë¬´ì‹œ (ì´ë¯¸ ì²˜ë¦¬ëœ í„´)
            if not self.awaiting_final:
                logger.debug(f"STT final received but not awaiting_final, turn_id={self.turn_id}")
                return
            
            # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì·¨ì†Œ
            if self.final_timeout_task and not self.final_timeout_task.done():
                self.final_timeout_task.cancel()
                self.final_timeout_task = None
            
            # ìµœì¢… í…ìŠ¤íŠ¸ ê²°ì • (final í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ëˆ„ì  ë²„í¼ ì‚¬ìš©)
            final_text = text_clean if text_clean else self.turn_text_buffer.strip()
            if not final_text:
                final_text = "[inaudible]"
            
            text_len = len(final_text)
            logger.info(f"âœ… STT_FINAL turn_id={self.turn_id} text_len={text_len} text=\"{final_text}\"")
            
            # awaiting_final í”Œë˜ê·¸ í•´ì œ
            self.awaiting_final = False
            current_turn_id = self.turn_id
            
            # í”„ë¡ íŠ¸ì—”ë“œë¡œ final ì „ì†¡
            await self.send_json({
                "type": "stt.final",
                "turn_id": current_turn_id,
                "text": final_text
            })
        
        # ë½ í•´ì œ í›„ LLM í˜¸ì¶œ
        await self._call_llm_for_turn(current_turn_id, final_text)
    
    async def _on_stt_error(self, error: Exception):
        """STT ì—ëŸ¬ ì²˜ë¦¬"""
        logger.error(f"STT error: {error}", exc_info=True)
        await self.send_json({
            "type": "stt.error",
            "message": str(error)
        })
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info(f"Cleaning up session: {self.session_id}")
        
        # í„´ ìƒíƒœ ì •ë¦¬ (íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì·¨ì†Œ)
        async with self._turn_lock:
            if self.final_timeout_task and not self.final_timeout_task.done():
                self.final_timeout_task.cancel()
                try:
                    await self.final_timeout_task
                except asyncio.CancelledError:
                    pass
                self.final_timeout_task = None
        
        # server_vad ëª¨ë“œ: Realtime STTê°€ í„´ì„ íŒë‹¨
        
        # STT ì›Œì»¤ ì •ë¦¬
        if self.receiver_task:
            self.receiver_task.cancel()
            try:
                await self.receiver_task
            except asyncio.CancelledError:
                pass
            self.receiver_task = None
        
        # STT í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ
        if self.stt_client:
            try:
                await self.stt_client.close()
            except Exception as e:
                logger.warning(f"Error closing STT client: {e}")
            self.stt_client = None
        
        # WebRTC ì—°ê²° ì¢…ë£Œ
        if self.pc:
            try:
                # ì—°ê²° ìƒíƒœ í™•ì¸ í›„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ
                if self.pc.connectionState != "closed":
                    await self.pc.close()
            except Exception as e:
                logger.warning(f"Error closing PeerConnection: {e}")
            finally:
                self.pc = None
        
        # ì˜¤ë””ì˜¤ ì†¡ì¶œ íŠ¸ë™ ì¢…ë£Œ
        if self.audio_sender:
            try:
                self.audio_sender.close()
            except Exception as e:
                logger.warning(f"Error closing audio sender: {e}")
            finally:
                self.audio_sender = None
